{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Models Individually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "test_folder = '102flowers_segmen_split/test'\n",
    "\n",
    "\n",
    "# Define transformations for the test dataset\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ResNet18 expects 224x224 input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Standard normalization for ResNet\n",
    "])\n",
    "\n",
    "\n",
    "# Load the test dataset\n",
    "test_folder = '102flowers_segmen_split/test'\n",
    "test_dataset = ImageFolder(test_folder, transform=test_transforms)\n",
    "\n",
    "# Create a DataLoader for the test dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the device for the testing script\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alici\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\alici\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 73.2314\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "vgg_16 = models.vgg16(pretrained=False)\n",
    "num_features = vgg_16.classifier[6].in_features\n",
    "vgg_16.classifier[6] = nn.Linear(num_features, 102)\n",
    "vgg_16.load_state_dict(torch.load('model_vgg16(8).pth'))\n",
    "\n",
    "# Move the model to the device\n",
    "vgg_16 = vgg_16.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "vgg_16.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = vgg_16(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "vgg16_accuracy = correct / total * 100\n",
    "print(f'Accuracy of the network on the test images: {vgg16_accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 71.0522\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "vgg_19 = models.vgg19(pretrained=False)\n",
    "num_features = vgg_19.classifier[6].in_features\n",
    "vgg_19.classifier[6] = nn.Linear(num_features, 102)\n",
    "vgg_19.load_state_dict(torch.load('model_vgg19(13).pth'))\n",
    "\n",
    "# Move the model to the device\n",
    "vgg_19 = vgg_19.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "vgg_19.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = vgg_19(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "vgg19_accuracy = correct / total * 100\n",
    "print(f'Accuracy of the network on the test images: {vgg19_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 64.3194\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "resnet_18 = models.resnet18(pretrained=False)\n",
    "num_features = resnet_18.fc.in_features\n",
    "resnet_18.fc = nn.Linear(num_features, 102)\n",
    "resnet_18.load_state_dict(torch.load('resnet_18(5).pth'))\n",
    "\n",
    "# Move the model to the device\n",
    "resnet_18 = resnet_18.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "resnet_18.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = resnet_18(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "resnet18_accuracy = correct / total * 100\n",
    "print(f'Accuracy of the network on the test images: {resnet18_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DeiTForImageClassification were not initialized from the model checkpoint at facebook/deit-base-distilled-patch16-224 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 80.3708\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "from transformers import DeiTForImageClassification\n",
    "\n",
    "model_deit = DeiTForImageClassification.from_pretrained(\n",
    "    'facebook/deit-base-distilled-patch16-224',\n",
    "    num_labels=102\n",
    ")\n",
    "model_deit.load_state_dict(torch.load('model_deit(2).pth'))\n",
    "\n",
    "# Move the model to the device\n",
    "model_deit = model_deit.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_deit.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model_deit(inputs)\n",
    "        _, preds = torch.max(outputs.logits, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "deit_accuracy = correct / total * 100\n",
    "print(f'Accuracy of the network on the test images: {deit_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 32 \n",
      "\n",
      "VGG16 Accuracy:  73.23141974304765\n",
      "VGG19 Accuracy:  71.05220361034314\n",
      "ResNet18 Accuracy:  64.31940152870385\n",
      "DeiT Accuracy:  80.37079199869898\n"
     ]
    }
   ],
   "source": [
    "print(\"Batch Size: 32\", \"\\n\")\n",
    "print(\"VGG16 Accuracy: \", vgg16_accuracy)\n",
    "print(\"VGG19 Accuracy: \", vgg19_accuracy)\n",
    "print(\"ResNet18 Accuracy: \", resnet18_accuracy)\n",
    "print(\"DeiT Accuracy: \", deit_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
